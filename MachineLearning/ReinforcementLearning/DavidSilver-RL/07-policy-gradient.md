# Policy Gradient

* Value Based: a policy was generated directly from the value function, e.g. using $\epsilon-greedy$
* Policy Based: we will directly parametrise the policy, $\pi_\theta(s,a)=\mathbb P(a|s, \theta)$
