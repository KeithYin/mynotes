# 学习资料总结

## 博客

* [http://www.wildml.com/](http://www.wildml.com/)
* [https://blog.openai.com/](https://blog.openai.com/)
* [http://colah.github.io/](http://colah.github.io/)
* ​


## CV

[https://www.pyimagesearch.com/](https://www.pyimagesearch.com/)

**公开课**

* udacity : introduction to computer vision
* cs231N



**CNN**

[http://colah.github.io/posts/2014-07-Conv-Nets-Modular/](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/)

http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/



[Non-Maximum Suppression (NMS)](https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/)



## NLP





## 基础

* [深度学习中的各种优化方法](http://ruder.io/optimizing-gradient-descent/index.html)
* [理解偏差与方差的 trade off](http://scott.fortmann-roe.com/docs/BiasVariance.html)
* [Why does Batch Normalization (for deep Neural Networks) fix the vanishing gradient problem?](https://www.quora.com/Why-does-Batch-Normalization-for-deep-Neural-Networks-fix-the-vanishing-gradient-problem)


