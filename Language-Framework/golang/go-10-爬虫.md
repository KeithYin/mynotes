# 爬虫

**http工作方式， HTTP 协议在 应用层，基于 TCP**

* HTTP 是用来解析 `TCP` 层传输的数据的
* 直接用 `TCP` 进行 B/S 编程的话，需要自己写代码解析报文信息，使用 `HTTP` 协议就更简单了

```
当浏览器输入 www.baidu.com时底层发生了什么

1. client --> DNS server : 获取 www.baidu.com 对应的  url 地址
2. client 通过 url 访问 web 服务器
```



**客户端请求包**

```
#GET / HTTP/1.1   --> 请求行
Host: 127.0.0.1:8000   ---> 请求头
Connection: keep-alive ---> 请求头

```

**响应包**



**HTTP编程---服务器**

```go
package main

import (
	"fmt"
    "net/http"
)

func HandleConn(w http.ResponseWriter, req *http.Request){
    // w: 用于给客户端回复数据
    // req: 用来读取客户端发来的数据
    w.Write([]byte("hello go"))
}

func main(){
    // 注册处理函数，用户连接，自动调用指定的处理函数
    // 第一个参数代表为 哪个请求 定义的 回调函数
    http.HandleFunc("/", HandConn)
    
    // 监听绑定
    http.ListenAndServe(":8000", nil)
}
```


**客户端编程**

```go
package main
import (
	"fmt"
    "net/http"
)
func main(){
    resp, err1 := http.Get("http://www.baidu.com")
    defer resp.Body.Close()
    
    buf := make([]byte, 4*1024)
    
    for {
        n, err2 := resp.Body.Read(buf)
        if n == 0{
            break
        }
    }
}

```

### 几个抽象

* Client: 理解为 浏览器客户端
* Request: http 的请求
* Respnose: http 的响应内容


### 爬虫

* 明确目标
* 爬（将目标网站的内容爬取下来）
* 取（去掉没有用处的数据）
* 处理数据（按照我们想要的方式存储和使用）

```go
// 搞 百度贴吧
package main

import (
	"fmt"
    "net/http"
)

func getPage(url string)(result string, err error){
    resp, err1 := http.Get(url)
    if err1 != nil{
        err = err1
       	return
    }
    
    defer resp.Body.Close()
    
    // 读取网页 body 内容
    buf := make([]byte, 4*1024)
    
    for{
        n, _ := resp.Body.Read(buf)
    }
    
}

func main(){
    for i:=0; i<5; i++{
        getPage("http://www.baidu.com")
    }
}
```



# Details

`http`包对于 HTTP 请求的三个抽象：`http.Client`, `http.Request`, `http.RoundTripper`



* `http.Client`
  * http client：目的是发 http 请求包，接收 http 响应包
  * The Client's Transport typically has internal state (cached TCP connections), so Clients should be reused instead of created as needed. 

* `http.Request` 

  * 作为 client request：可以设置 http 请求包的一些 值
  * 作为 server request：可以访问 http 请求包的 一些信息

* `http.RoundTripper`, 是个接口:

  * execute a single HTTP transaction, obtaining the Response for a given Request.
  * `RoundTrip(*Request) (*Response, error)`

* `http.Transport`: `RoundTripper`的一个实现
  * 配置 HTTP 请求的一些偏底层的属性


```go
var DefaultTransport RoundTripper = &Transport{
    Proxy: ProxyFromEnvironment,
    DialContext: (&net.Dialer{
        Timeout:   30 * time.Second,
        KeepAlive: 30 * time.Second,
        DualStack: true,
    }).DialContext,
    MaxIdleConns:          100,
    IdleConnTimeout:       90 * time.Second,
    TLSHandshakeTimeout:   10 * time.Second,
    ExpectContinueTimeout: 1 * time.Second,
}
```



**Demo3：设置 cookie**

[cookieJar用法](https://gist.github.com/HugoPresents/a8a44c3c4cd514052952)

* `http.Request.Header` 是个 `map[string][]string` 类型，
* `Header` 里面是用来设置 `HTTP` 请求头中的参数的

```go
// Header 是个 map[string][]string
http.Request.Header["Cookie"] = "...; ...; ...;"
```

```
/p/aj/v6/mblog/mbloglist?ajwvr=6&domain=100505&rightmod=1&wvr=6&mod=personinfo&is_all=1&pagebar=0&pl_name=Pl_Official_MyProfileFeed__20&id=1005053093406867&script_uri=/3093406867/profile&feed_type=0&page=1&pre_page=1&domain_op=100505&__rnd=1541344763507


/p/aj/v6/mblog/mbloglist?ajwvr=6&domain=100505&rightmod=1&wvr=6&mod=personinfo&is_all=1&pagebar=1&pl_name=Pl_Official_MyProfileFeed__20&id=1005053093406867&script_uri=/3093406867/profile&feed_type=0&page=1&pre_page=1&domain_op=100505&__rnd=1541345109856
```



需要注意的几个点

* **Clients and Transports are safe for concurrent use by multiple goroutines and for efficiency should only be created once and re-used. If the Body is not closed, the Client's underlying RoundTripper (typically Transport) may not be able to re-use a persistent TCP connection to the server for a subsequent "keep-alive" request.**
* **The client must close the response body when finished with it**
  * `defer response.Body.Close()`
  
## 碰到的问题
```go
fenfaData, err := http.Get(uri)
if err != nil {
	fmt.Println(err)
}
defer fenfaData.Body.Close()

var info string
for {
	n, err := fenfaData.Body.Read(buf)
	if err != nil { //使用此判断, 会直接EOF, 不知道为啥
		fmt.Println("error: ", err)
		break
	}
	if n == 0 { // 只使用 n == 0 判断是可以正常的获取数据的
		fmt.Println("n=0, EOF")
		break
	}
	curLine := string(buf)
	info += curLine
}
```
