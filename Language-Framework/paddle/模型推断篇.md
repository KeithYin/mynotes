1. load_inference_model 之后还要 load_persistables?
2.

如何个 load_inference_model 返回的 infer_program 添加额外的 feed 和 fetch 操作

参考代码 Executor._add_feed_fetch_ops 

```python
with fluid.scope_guard(scope):
    infer_program, feed_names, fetch_targets = fluid.io.load_inference_model(
        executor=exe, dirname=model_param_dir)
    fluid.io.load_persistables(exe, model_param_dir, main_program=infer_program)

with fluid.program_guard(infer_program):
    additional_inp = fluid.layers.data(name="additional_inp", shape=[1], append_batch_size=False)

fetch_var = infer_program.global_block().var("fetch")
infer_program.global_block().append_op(
                type='fetch',
                inputs={'X': [additional_inp]},
                outputs={'Out': [fetch_var]},
                attrs={'col': len(fetch_targets)})
fetch_targets = fetch_targets + [additional_inp]
# print(infer_program)

res = exe.run(program=infer_program, feed={additional_inp.name: np.array([4.])}, 
    fetch_list=fetch_targets)

```
